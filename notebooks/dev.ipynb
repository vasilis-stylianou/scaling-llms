{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d4f8273",
   "metadata": {},
   "source": [
    "# DataManager Development Notebook\n",
    "\n",
    "Testing data loading with DataManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "847d6706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from scaling_llms.data import DataManager, DATA_SOURCES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc9c4de",
   "metadata": {},
   "source": [
    "## Create DataManager and Load Tiny Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27292776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available data sources:\n",
      "['tiny_shakespeare', 'wikitext103', 'openwebtext']\n"
     ]
    }
   ],
   "source": [
    "# Create DataManager\n",
    "dm = DataManager(data_dir=\"../data\", seed=1337)\n",
    "\n",
    "# List available sources\n",
    "print(\"Available data sources:\")\n",
    "print(dm.list_data_sources())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51a0e787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data:  21%|██▏       | 17/80 [03:11<11:48, 11.24s/files]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load Tiny Shakespeare\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m train_iter, val_iter = \u001b[43mdm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loaders\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mDATA_SOURCES\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopenwebtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_frac\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mas_iterable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use 0 for notebook to avoid multiprocessing issues\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoaders created successfully!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/scaling-llms/src/scaling_llms/data.py:31\u001b[39m, in \u001b[36mget_loaders\u001b[39m\u001b[34m(self, source, seq_len, batch_size, val_frac, num_workers, pin_memory, persistent_workers, as_iterable, resume_step, seed, max_samples, val_split)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minfinite_dataloader\u001b[39m(loader):\n\u001b[32m     30\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Yield batches from `loader` indefinitely.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \n\u001b[32m     32\u001b[39m \u001b[33;03m    Useful for training loops that want an endless stream of batches.\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     35\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m loader:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/scaling-llms/src/scaling_llms/data.py:75\u001b[39m, in \u001b[36mload_dataset_bytes\u001b[39m\u001b[34m(dataset_name, dataset_config, split, max_samples, text_separator)\u001b[39m\n\u001b[32m     73\u001b[39m     dataset = load_dataset(dataset_name, dataset_config, split=split)\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     dataset = \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m=\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# Apply max_samples limit if specified\u001b[39;00m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m max_samples \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m max_samples < \u001b[38;5;28mlen\u001b[39m(dataset):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/scaling-llms/.venv/lib/python3.11/site-packages/datasets/load.py:1508\u001b[39m, in \u001b[36mload_dataset\u001b[39m\u001b[34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, **config_kwargs)\u001b[39m\n\u001b[32m   1505\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m builder_instance.as_streaming_dataset(split=split)\n\u001b[32m   1507\u001b[39m \u001b[38;5;66;03m# Download and prepare data\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1508\u001b[39m \u001b[43mbuilder_instance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1509\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1510\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1511\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1512\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1513\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1514\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# Build dataset for splits\u001b[39;00m\n\u001b[32m   1517\u001b[39m keep_in_memory = (\n\u001b[32m   1518\u001b[39m     keep_in_memory \u001b[38;5;28;01mif\u001b[39;00m keep_in_memory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m is_small_dataset(builder_instance.info.dataset_size)\n\u001b[32m   1519\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/scaling-llms/.venv/lib/python3.11/site-packages/datasets/builder.py:884\u001b[39m, in \u001b[36mDatasetBuilder.download_and_prepare\u001b[39m\u001b[34m(self, output_dir, download_config, download_mode, verification_mode, dl_manager, base_path, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[39m\n\u001b[32m    882\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_proc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    883\u001b[39m     prepare_split_kwargs[\u001b[33m\"\u001b[39m\u001b[33mnum_proc\u001b[39m\u001b[33m\"\u001b[39m] = num_proc\n\u001b[32m--> \u001b[39m\u001b[32m884\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdownload_and_prepare_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[38;5;66;03m# Sync info\u001b[39;00m\n\u001b[32m    891\u001b[39m \u001b[38;5;28mself\u001b[39m.info.dataset_size = \u001b[38;5;28msum\u001b[39m(split.num_bytes \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.info.splits.values())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/scaling-llms/.venv/lib/python3.11/site-packages/datasets/builder.py:925\u001b[39m, in \u001b[36mDatasetBuilder._download_and_prepare\u001b[39m\u001b[34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[39m\n\u001b[32m    923\u001b[39m split_dict = SplitDict(dataset_name=\u001b[38;5;28mself\u001b[39m.dataset_name)\n\u001b[32m    924\u001b[39m split_generators_kwargs = \u001b[38;5;28mself\u001b[39m._make_split_generators_kwargs(prepare_split_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m split_generators: \u001b[38;5;28mlist\u001b[39m[SplitGenerator] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_split_generators\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msplit_generators_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[38;5;66;03m# Checksums verification\u001b[39;00m\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verification_mode == VerificationMode.ALL_CHECKS \u001b[38;5;129;01mand\u001b[39;00m dl_manager.record_checksums:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/scaling-llms/.venv/lib/python3.11/site-packages/datasets/packaged_modules/parquet/parquet.py:110\u001b[39m, in \u001b[36mParquet._split_generators\u001b[39m\u001b[34m(self, dl_manager)\u001b[39m\n\u001b[32m    108\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAt least one data file must be specified, but got data_files=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.config.data_files\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    109\u001b[39m dl_manager.download_config.extract_on_the_fly = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m data_files = \u001b[43mdl_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m splits = []\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m split_name, files \u001b[38;5;129;01min\u001b[39;00m data_files.items():\n\u001b[32m    113\u001b[39m     \u001b[38;5;66;03m# Infer features if they are stored in the arrow schema\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/scaling-llms/.venv/lib/python3.11/site-packages/datasets/download/download_manager.py:159\u001b[39m, in \u001b[36mDownloadManager.download\u001b[39m\u001b[34m(self, url_or_urls)\u001b[39m\n\u001b[32m    157\u001b[39m start_time = datetime.now()\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m stack_multiprocessing_download_progress_bars():\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m     downloaded_path_or_paths = \u001b[43mmap_nested\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdownload_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl_or_urls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmap_tuple\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDownloading data files\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatched\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m duration = datetime.now() - start_time\n\u001b[32m    169\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDownloading took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mduration.total_seconds()\u001b[38;5;250m \u001b[39m//\u001b[38;5;250m \u001b[39m\u001b[32m60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m min\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/scaling-llms/.venv/lib/python3.11/site-packages/datasets/utils/py_utils.py:503\u001b[39m, in \u001b[36mmap_nested\u001b[39m\u001b[34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, batched, batch_size, types, disable_tqdm, desc)\u001b[39m\n\u001b[32m    501\u001b[39m     num_proc = \u001b[32m1\u001b[39m\n\u001b[32m    502\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(v, types) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(v) > \u001b[38;5;28mlen\u001b[39m(iterable) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m iterable):\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m     mapped = \u001b[43m[\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmap_nested\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdata_struct\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[43m            \u001b[49m\u001b[43mparallel_min_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparallel_min_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbatched\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\n\u001b[32m    514\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m num_proc != -\u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m num_proc <= \u001b[32m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(iterable) < parallel_min_length:\n\u001b[32m    516\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m batched:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/scaling-llms/.venv/lib/python3.11/site-packages/datasets/utils/py_utils.py:504\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    501\u001b[39m     num_proc = \u001b[32m1\u001b[39m\n\u001b[32m    502\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(v, types) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(v) > \u001b[38;5;28mlen\u001b[39m(iterable) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m iterable):\n\u001b[32m    503\u001b[39m     mapped = [\n\u001b[32m--> \u001b[39m\u001b[32m504\u001b[39m         \u001b[43mmap_nested\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdata_struct\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[43m            \u001b[49m\u001b[43mparallel_min_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparallel_min_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbatched\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    513\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m    514\u001b[39m     ]\n\u001b[32m    515\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m num_proc != -\u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m num_proc <= \u001b[32m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(iterable) < parallel_min_length:\n\u001b[32m    516\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m batched:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/scaling-llms/.venv/lib/python3.11/site-packages/datasets/utils/py_utils.py:520\u001b[39m, in \u001b[36mmap_nested\u001b[39m\u001b[34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, batched, batch_size, types, disable_tqdm, desc)\u001b[39m\n\u001b[32m    518\u001b[39m         batch_size = \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mlen\u001b[39m(iterable) // num_proc + \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(iterable) % num_proc > \u001b[32m0\u001b[39m), \u001b[32m1\u001b[39m)\n\u001b[32m    519\u001b[39m     iterable = \u001b[38;5;28mlist\u001b[39m(iter_batched(iterable, batch_size))\n\u001b[32m--> \u001b[39m\u001b[32m520\u001b[39m mapped = \u001b[43m[\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_single_map_nested\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhf_tqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisable_tqdm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batched:\n\u001b[32m    525\u001b[39m     mapped = [mapped_item \u001b[38;5;28;01mfor\u001b[39;00m mapped_batch \u001b[38;5;129;01min\u001b[39;00m mapped \u001b[38;5;28;01mfor\u001b[39;00m mapped_item \u001b[38;5;129;01min\u001b[39;00m mapped_batch]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/scaling-llms/.venv/lib/python3.11/site-packages/datasets/utils/py_utils.py:521\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    518\u001b[39m         batch_size = \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mlen\u001b[39m(iterable) // num_proc + \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(iterable) % num_proc > \u001b[32m0\u001b[39m), \u001b[32m1\u001b[39m)\n\u001b[32m    519\u001b[39m     iterable = \u001b[38;5;28mlist\u001b[39m(iter_batched(iterable, batch_size))\n\u001b[32m    520\u001b[39m mapped = [\n\u001b[32m--> \u001b[39m\u001b[32m521\u001b[39m     \u001b[43m_single_map_nested\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    522\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m hf_tqdm(iterable, disable=disable_tqdm, desc=desc)\n\u001b[32m    523\u001b[39m ]\n\u001b[32m    524\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batched:\n\u001b[32m    525\u001b[39m     mapped = [mapped_item \u001b[38;5;28;01mfor\u001b[39;00m mapped_batch \u001b[38;5;129;01min\u001b[39;00m mapped \u001b[38;5;28;01mfor\u001b[39;00m mapped_item \u001b[38;5;129;01min\u001b[39;00m mapped_batch]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/scaling-llms/.venv/lib/python3.11/site-packages/datasets/utils/py_utils.py:389\u001b[39m, in \u001b[36m_single_map_nested\u001b[39m\u001b[34m(args)\u001b[39m\n\u001b[32m    382\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m function(data_struct)\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    384\u001b[39m     batched\n\u001b[32m    385\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, \u001b[38;5;28mdict\u001b[39m)\n\u001b[32m    386\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, types)\n\u001b[32m    387\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, (\u001b[38;5;28mdict\u001b[39m, types)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m data_struct)\n\u001b[32m    388\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mmapped_item\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miter_batched\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_struct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmapped_item\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[38;5;66;03m# Reduce logging to keep things readable in multiprocessing with tqdm\u001b[39;00m\n\u001b[32m    392\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m rank \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m logging.get_verbosity() < logging.WARNING:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/scaling-llms/.venv/lib/python3.11/site-packages/datasets/utils/py_utils.py:389\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    382\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m function(data_struct)\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    384\u001b[39m     batched\n\u001b[32m    385\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, \u001b[38;5;28mdict\u001b[39m)\n\u001b[32m    386\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, types)\n\u001b[32m    387\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, (\u001b[38;5;28mdict\u001b[39m, types)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m data_struct)\n\u001b[32m    388\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [mapped_item \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m iter_batched(data_struct, batch_size) \u001b[38;5;28;01mfor\u001b[39;00m mapped_item \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[32m    391\u001b[39m \u001b[38;5;66;03m# Reduce logging to keep things readable in multiprocessing with tqdm\u001b[39;00m\n\u001b[32m    392\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m rank \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m logging.get_verbosity() < logging.WARNING:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/scaling-llms/.venv/lib/python3.11/site-packages/datasets/download/download_manager.py:206\u001b[39m, in \u001b[36mDownloadManager._download_batched\u001b[39m\u001b[34m(self, url_or_filenames, download_config)\u001b[39m\n\u001b[32m    201\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    202\u001b[39m     max_workers = (\n\u001b[32m    203\u001b[39m         config.HF_DATASETS_MULTITHREADING_MAX_WORKERS \u001b[38;5;28;01mif\u001b[39;00m size < (\u001b[32m20\u001b[39m << \u001b[32m20\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m1\u001b[39m\n\u001b[32m    204\u001b[39m     )  \u001b[38;5;66;03m# enable multithreading if files are small\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mthread_map\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdownload_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl_or_filenames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_desc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDownloading\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m        \u001b[49m\u001b[43munit\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfiles\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmultiprocessing\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcurrent_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_identity\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# contains the ranks of subprocesses\u001b[39;49;00m\n\u001b[32m    212\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43menviron\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHF_DATASETS_STACK_MULTIPROCESSING_DOWNLOAD_PROGRESS_BARS\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    213\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmultiprocessing\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcurrent_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_identity\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    219\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m    220\u001b[39m         \u001b[38;5;28mself\u001b[39m._download_single(url_or_filename, download_config=download_config)\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m url_or_filename \u001b[38;5;129;01min\u001b[39;00m url_or_filenames\n\u001b[32m    222\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/scaling-llms/.venv/lib/python3.11/site-packages/tqdm/contrib/concurrent.py:69\u001b[39m, in \u001b[36mthread_map\u001b[39m\u001b[34m(fn, *iterables, **tqdm_kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[33;03mEquivalent of `list(map(fn, *iterables))`\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[33;03mdriven by `concurrent.futures.ThreadPoolExecutor`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     66\u001b[39m \u001b[33;03m    [default: max(32, cpu_count() + 4)].\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mconcurrent\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfutures\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ThreadPoolExecutor\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_executor_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mThreadPoolExecutor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43miterables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/scaling-llms/.venv/lib/python3.11/site-packages/tqdm/contrib/concurrent.py:51\u001b[39m, in \u001b[36m_executor_map\u001b[39m\u001b[34m(PoolExecutor, fn, *iterables, **tqdm_kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ensure_lock(tqdm_class, lock_name=lock_name) \u001b[38;5;28;01mas\u001b[39;00m lk:\n\u001b[32m     48\u001b[39m     \u001b[38;5;66;03m# share lock in case workers are already using `tqdm`\u001b[39;00m\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m PoolExecutor(max_workers=max_workers, initializer=tqdm_class.set_lock,\n\u001b[32m     50\u001b[39m                       initargs=(lk,)) \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43miterables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/scaling-llms/.venv/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.11/concurrent/futures/_base.py:619\u001b[39m, in \u001b[36mExecutor.map.<locals>.result_iterator\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[32m    617\u001b[39m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[32m    618\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    620\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    621\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs.pop(), end_time - time.monotonic())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.11/concurrent/futures/_base.py:317\u001b[39m, in \u001b[36m_result_or_cancel\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    316\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    319\u001b[39m         fut.cancel()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.11/concurrent/futures/_base.py:451\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m    449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__get_result()\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_condition\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.11/threading.py:320\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    319\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    321\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    322\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Load Tiny Shakespeare\n",
    "train_iter, val_iter = dm.get_loaders(\n",
    "    DATA_SOURCES.openwebtext,\n",
    "    seq_len=128,\n",
    "    batch_size=4,\n",
    "    val_frac=0.1,\n",
    "    as_iterable=True,\n",
    "    num_workers=0  # Use 0 for notebook to avoid multiprocessing issues\n",
    ")\n",
    "\n",
    "print(\"Loaders created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "201cd4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shapes: x=torch.Size([4, 128]), y=torch.Size([4, 128])\n",
      "\n",
      "First sequence (x):\n",
      "tensor([128, 148,  32, 105, 110,  32, 111, 110, 101,  32, 110, 105, 103, 104,\n",
      "        116,  32,  44,  32,  98, 117, 116,  32, 104, 105, 115,  32,  97, 105,\n",
      "        114,  99, 114,  97, 102, 116,  32, 119,  97, 115,  32, 100,  97, 109,\n",
      "         97, 103, 101, 100,  32,  98, 121,  32, 114, 101, 116, 117, 114, 110,\n",
      "         32, 102, 105, 114, 101,  32,  44,  32, 114, 101, 113, 117, 105, 114,\n",
      "        105, 110, 103,  32,  97,  32, 102, 111, 114,  99, 101, 100,  32, 108,\n",
      "         97, 110, 100, 105, 110, 103,  32,  46,  32,  72, 101,  32, 117, 115,\n",
      "        101, 100,  32, 111, 110, 108, 121,  32,  50,  50,  32,  99,  97, 110,\n",
      "        110, 111, 110,  32, 115, 104, 101, 108, 108, 115,  32, 116, 111,  32,\n",
      "        100, 111])\n",
      "\n",
      "Target sequence (y):\n",
      "tensor([148,  32, 105, 110,  32, 111, 110, 101,  32, 110, 105, 103, 104, 116,\n",
      "         32,  44,  32,  98, 117, 116,  32, 104, 105, 115,  32,  97, 105, 114,\n",
      "         99, 114,  97, 102, 116,  32, 119,  97, 115,  32, 100,  97, 109,  97,\n",
      "        103, 101, 100,  32,  98, 121,  32, 114, 101, 116, 117, 114, 110,  32,\n",
      "        102, 105, 114, 101,  32,  44,  32, 114, 101, 113, 117, 105, 114, 105,\n",
      "        110, 103,  32,  97,  32, 102, 111, 114,  99, 101, 100,  32, 108,  97,\n",
      "        110, 100, 105, 110, 103,  32,  46,  32,  72, 101,  32, 117, 115, 101,\n",
      "        100,  32, 111, 110, 108, 121,  32,  50,  50,  32,  99,  97, 110, 110,\n",
      "        111, 110,  32, 115, 104, 101, 108, 108, 115,  32, 116, 111,  32, 100,\n",
      "        111, 119])\n",
      "\n",
      "Decoded text (first 100 chars):\n",
      "�� in one night , but his aircraft was damaged by return fire , requiring a forced landing . He used\n"
     ]
    }
   ],
   "source": [
    "# Get a batch from train iterator\n",
    "x_batch, y_batch = next(train_iter)\n",
    "\n",
    "print(f\"Batch shapes: x={x_batch.shape}, y={y_batch.shape}\")\n",
    "print(f\"\\nFirst sequence (x):\")\n",
    "print(x_batch[0])\n",
    "print(f\"\\nTarget sequence (y):\")\n",
    "print(y_batch[0])\n",
    "print(f\"\\nDecoded text (first 100 chars):\")\n",
    "text = bytes(x_batch[0].tolist()).decode('utf-8', errors='replace')\n",
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65028ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (scaling-llms)",
   "language": "python",
   "name": "scaling-llms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
